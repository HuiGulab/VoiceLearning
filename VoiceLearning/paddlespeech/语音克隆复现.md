## paddlespeech语音克隆复现

### Git clone PaddleSpeech

你需要先 git clone 本仓库

```
git clone https://github.com/PaddlePaddle/PaddleSpeech.git
cd PaddleSpeech
```

### 数据集下载

使用AISHEEL-3数据集，从[官网](http://www.aishelltech.com/aishell_3)中下载，解压到 `~/datasets `文件夹中，`~`是当前登录用户的用户目录，比如`/home/oyb/`，然后数据集就在 `~/datasets/data_aishell3 `文件夹中。

注：官网下载的很慢可以复制地址到迅雷中下载，可以更快一点

### 获取MFA结果

**MFA** (Montreal Forced Aligner )是用于获得话语和音素序列之间的对齐，我们使用[MFA2.x](https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner)来获得aishell3的结果，你可以从[aishell3_alignment_tone.tar.gz](https://paddlespeech.bj.bcebos.com/MFA/AISHELL-3/with_tone/aishell3_alignment_tone.tar.gz) 下载获取好的结果，或者训练你自己的MFA参考我们仓库的[mfa example](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/mfa) 

### 预训练的 GE2E 模型

我们使用预训练的 GE2E 模型为每个句子生成说话人嵌入。

从这里下载预训练的 GE2E 模型[ge2e_ckpt_0.3.zip](https://bj.bcebos.com/paddlespeech/Parakeet/released_models/ge2e/ge2e_ckpt_0.3.zip) 并解压它。

### 开始使用

切换到项目所在目录

```
cd examples/aishell3/vc1/
```

确保数据集的目录在 `~/datasets/data_aishell3`. AISHELL-3的MFA结果路径在 `./aishell3_alignment_tone`. 预训练的GE2E模型路径在 `./ge2e_ckpt_0.3`. 

运行`run.sh`文件即可运行，所有的运行命令都在里面，不过这样很容易出错建议一步一步来，`run.sh`里有四个步骤，每个步骤都有它特定的功能

| Stage | Function |
| ----- | -------- |
| 0     | 数据处理 |
| 1     | 训练模型 |
| 2     | 合成     |
| 3     | 语音克隆 |

您可以通过设置`stage `和`stop_stage `来选择运行一系列阶段。

例如，如果你想执行阶段 2 和阶段 3 的代码，你可以运行这个脚本：

```
./run.sh --stage 2 --stop-stage 3
```

或者您可以设置`stage`等于`stop-stage`只运行一个阶段。例如，如果你只想运行`stage 0`，你可以使用下面的脚本： 

```
./run.sh --stage 0 --stop-stage 0
```

下面将详细描述`run.sh`中的各个阶段。 

#### 数据处理

执行

```
./run.sh --stage 0 --stop-stage 0
```

会调用`./local/preprocess.sh`进行数据处理，执行完成后会生成一个`dump`文件夹，`dump`文件夹的目录结构如下：

```
dump
├── dev
│   ├── norm
│   └── raw
├── embed
│   ├── SSB0005
│   ├── SSB0009
│   ├── ...
│   └── ...
├── phone_id_map.txt
├── speaker_id_map.txt
├── test
│   ├── norm
│   └──  raw
└── train
    ├── energy_stats.npy
    ├── norm
    ├── pitch_stats.npy
    ├── raw
    └── speech_stats.npy
```

包含为 AISHELL-3 中每个句子生成的`embed`说话人嵌入，它与 wav 文件具有相同的文件结构，格式为 `.npy`.

数据集分为 3 个部分，即`train`、`dev`和` test`，每个部分包含一个`norm`和`raw`子文件夹。raw文件夹包含每个话语的语音、音高和能量特征，而norm文件夹包含标准化的。用于归一化特征的统计数据是从位于 中的训练集计算出来的`dump/train/*_stats.npy`。

此外，`metadata.jsonl`每个子文件夹中都有一个。它是一个类似表格的文件，包含音素、text_lengths、speech_lengths、持续时间、语音特征路径、音高特征路径、能量特征路径、说话者和每个话语的 id。

此步骤大约会执行两个多小时。

#### 模型训练

执行

```
./run.sh --stage 1 --stop-stage 1
```

会调用`./local/train.sh`进行训练，训练完成之后默认会在`./exp/default`文件夹中生成checkpoint文件夹，里面保存了训练出来的模型。

此过程大约要训练一天。

#### 合成

我们使用[parallel wavegan](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell3/voc1)作为神经声码器。从[pwg_aishell3_ckpt_0.5.zip](https://paddlespeech.bj.bcebos.com/Parakeet/released_models/pwgan/pwg_aishell3_ckpt_0.5.zip)下载预训练的parallel wavegan 模型并解压到当前文件夹中。 

执行

```
./run.sh --stage 2 --stop-stage 2
```

会调用`./local/synthesize.sh`这会从 `metadata.jsonl`中合成语音波形. ，训练完成之后会在`./exp/test`文件夹中生成合成的语音。好像不执行这一步也能进行下一步的语音克隆。

#### 语音克隆

假设需要克隆的音频在`./ref_audio`中 

执行

```
./run.sh --stage 3 --stop-stage 3
```

会调用`./local/voice_cloning.sh`进行语音克隆，训练完成之后会在`./exp/vc_syn`文件夹中生成克隆的语音。这一步可能需要在`run.sh`中修改一些参数

```
...
ckpt_name=snapshot_iter_96400.pdz # 改为checkpoint里训练出来的文件
...
```

在`voice_cloning.sh `可以修改文本。

### 预训练模型

paddlespeech提供了预训练模型

- [fastspeech2_nosil_aishell3_vc1_ckpt_0.5.zip](https://paddlespeech.bj.bcebos.com/Parakeet/released_models/fastspeech2/fastspeech2_nosil_aishell3_vc1_ckpt_0.5.zip)

如果电脑配置不行或者只想体验一下效果可以下载预训练模型，直接执行语音克隆这一步（需要修改参数）。

预训练模型文件结构及相关参数如下

```
fastspeech2_nosil_aishell3_ckpt_vc1_0.5
├── default.yaml            # default config used to train fastspeech2
├── phone_id_map.txt        # phone vocabulary file when training fastspeech2
├── snapshot_iter_96400.pdz # model parameters and optimizer states
└── speech_stats.npy        # statistics used to normalize spectrogram when training fastspeech2
```

| Model   | Step           | eval/loss | eval/l1_loss | eval/duration_loss | eval/pitch_loss | eval/energy_loss |
| ------- | -------------- | --------- | ------------ | ------------------ | --------------- | ---------------- |
| default | 2(gpu) x 96400 | 0.99699   | 0.62013      | 0.53057            | 0.11954         | 0.20426          |